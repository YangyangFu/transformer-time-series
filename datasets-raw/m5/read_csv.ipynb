{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "This is to read raw data and merge/organize for dataloader.\n",
    "The output format of sales is expected to be a dataframe with rows for timesteps, and columns as the time series id that needs to be predicted. \n",
    "Thus, the sales dataframe should be 1941x30490 for item-by-item organization. \n",
    "If add aggregations, the shape should be 1941x42840.\n",
    "\n",
    "To distinguish the timeseries, we need save another dataframe as a header to map the timeseries id to its `state_id, store_id, cat_id, dept_id, item_id`.\n",
    "\n",
    "\n",
    "This type of organization is good for channel-independent algorithms, which considers each time-series as an independent channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "import joblib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/yyf/miniconda3/envs/tts-tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting git+https://github.com/YangyangFu/transformer-time-series@main\n",
      "  Cloning https://github.com/YangyangFu/transformer-time-series (to revision main) to /tmp/pip-req-build-4n72acqg\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/YangyangFu/transformer-time-series /tmp/pip-req-build-4n72acqg\n",
      "  Resolved https://github.com/YangyangFu/transformer-time-series to commit c7b930944f10ccc1f08284b080c4dbf61b356aab\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: tsl\n",
      "  Building wheel for tsl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tsl: filename=tsl-1.0-py3-none-any.whl size=53908 sha256=d4679f069b571db62547f85473b643e165ead74473c899aca1abba318c7c6390\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ib9tox11/wheels/d1/ce/7e/249bc100ae340cfeae1d7b80e6f993ac1923811606147a4941\n",
      "Successfully built tsl\n",
      "Installing collected packages: tsl\n",
      "Successfully installed tsl-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/YangyangFu/transformer-time-series@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tsl.utils.utils import reduce_mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(df, name, path):\n",
    "    df = reduce_mem_usage(df)\n",
    "    save_dir = pathlib.Path(path)\n",
    "    if not save_dir.exists():\n",
    "        save_dir.mkdir(parents=True)\n",
    "    joblib.dump(df, save_dir / f'{name}.joblib', compress=True)\n",
    "\n",
    "dump_dir = os.path.join('./data', 'individual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./raw-data/m5-forecasting-uncertainty/\"\n",
    "\n",
    "sales_file = \"sales_train_evaluation.csv\"\n",
    "calendar_file = \"calendar.csv\"\n",
    "price_file = \"sell_prices.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(os.path.join(data_dir, sales_file))\n",
    "calendar = pd.read_csv(os.path.join(data_dir, calendar_file), parse_dates=[\"date\"])\n",
    "price = pd.read_csv(os.path.join(data_dir, price_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales.columns)\n",
    "print(calendar.columns)\n",
    "print(price.columns)\n",
    "print(sales.shape, calendar.shape, price.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global time features and time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sales.drop(id_cols, axis=1)\n",
    "s.index = sales['id']\n",
    "s = s.transpose()\n",
    "s = s.reset_index()\n",
    "s = s.rename(columns={'index': 'd'})\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.merge(calendar[['d', 'date']], how = 'outer')\n",
    "s = s.drop(['d'], axis=1)\n",
    "s.index = s['date']\n",
    "s = s.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape, s.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(s, 'ts', dump_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-invariant local features\n",
    "Time-invariant local features refer to the features that are dependent on the time series itself but not on time, such as `item_id, store_id`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = sales[id_cols]\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need convert to integers using label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for col in items.columns:\n",
    "    encoder = LabelEncoder()\n",
    "    items[col] = encoder.fit_transform(items[col])\n",
    "    label_encoders[col] = encoder\n",
    "\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(items, 'local_invariant', dump_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-variant local features\n",
    "\n",
    "local features that is time variant are `SNAP`, `item sell price`, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snap is a local feature based on states. it will be different for each time series.\n",
    "\n",
    "the targets are each item in each store in each state, thus, each item should have their own SNAP feature based on the states it locates.\n",
    "\n",
    "here I create a snap table for each time series, so that during training, we can grab the snap for corresponding target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = calendar[['date', 'snap_CA', 'snap_TX', 'snap_WI']]\n",
    "snap = snap.rename(columns={'snap_CA':'CA',\n",
    "             'snap_TX':'TX',\n",
    "             'snap_WI':'WI'})\n",
    "snap = pd.concat([snap, pd.DataFrame(columns=items['id'])])\n",
    "for idx, state in zip(items['id'], items['state_id']):\n",
    "    snap[idx] = snap[state]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap.index = snap['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = snap.drop(['CA', 'TX', 'WI', 'date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap.shape, snap.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(snap, 'local_variant_snap', dump_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del snap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price for each item, should serve as a numerical time-variant local feature.\n",
    "\n",
    "The price is represented on a weekly basis, while the sales is represent on a daily basis. \n",
    "Thus, we need manipulate the weekly price to daily price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.head(), price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some items are only for sale after a specific date.\n",
    "# here we have a release date to consider this effect\n",
    "releases = price.groupby(['store_id','item_id'])['wm_yr_wk'].min().reset_index()\n",
    "releases.columns = ['store_id','item_id','wm_yr_wk']\n",
    "weekday = calendar.groupby('wm_yr_wk')['date'].min().reset_index()\n",
    "releases = releases.merge(weekday)\n",
    "releases.columns = ['store_id','item_id','release_week', 'release_date']\n",
    "releases.drop('release_week', axis=1, inplace=True)\n",
    "releases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.columns\n",
    "pr = price.merge(releases)\n",
    "pr.columns, pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pr.merge(calendar[['wm_yr_wk', 'd', 'date']])\n",
    "pr = pr.merge(items)\n",
    "pr.columns, pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr['released'] = (pr['date'] >= pr['release_date']).astype(int)\n",
    "pr = pr.drop(['wm_yr_wk', 'item_id', 'store_id', 'sell_price', 'dept_id', 'cat_id','state_id'], axis=1)\n",
    "pr = pr.pivot(index='date', columns='id', values='release_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are some `NaT` in the columns, checkout why???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.shape, pr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pr[items['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pr.apply(lambda x: x <= pr.index, axis=0)\n",
    "pr = pr.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.head(), pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(pr, 'local_variant_release', dump_dir)\n",
    "del pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price.merge(calendar[['wm_yr_wk', 'd', 'date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.head(), price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price.merge(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.head(), price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price.pivot(index='date', columns='id', values='sell_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.head(), price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price[items['id']]\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price.fillna(value=0)\n",
    "dump(price, 'local_variant_price', dump_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note some items are not for sales within the given time period, thus the prices are `NAN`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noticed, there are a lot of zeros/NAN in the price, which basically due to \"out of stock\" or \"not released\". However, we dont have information to indicate if a zero/NAN price is due to out of stock. \n",
    "\n",
    "Based on the original price data, we can see some items only have price info after specific date. We will set that date as the release date. \n",
    "\n",
    "The NANs for testing during `d1942-d1969` are due to the fact that the testing data is not openly accessible during competition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
